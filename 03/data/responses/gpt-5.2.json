[
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_01",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS event_count\nFROM events;",
    "raw_response": "SELECT count() AS event_count\nFROM events;",
    "tokens_in": 362,
    "tokens_out": 14,
    "latency_ms": 542,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_01",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS event_count\nFROM events;",
    "raw_response": "SELECT count() AS event_count\nFROM events;",
    "tokens_in": 362,
    "tokens_out": 14,
    "latency_ms": 510,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_01",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS event_count\nFROM events;",
    "raw_response": "SELECT count() AS event_count\nFROM events;",
    "tokens_in": 362,
    "tokens_out": 14,
    "latency_ms": 525,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_02",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nORDER BY timestamp DESC, event_id DESC\nLIMIT 10;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nORDER BY timestamp DESC, event_id DESC\nLIMIT 10;",
    "tokens_in": 361,
    "tokens_out": 61,
    "latency_ms": 533,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_02",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nORDER BY timestamp DESC, event_id DESC\nLIMIT 10;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nORDER BY timestamp DESC, event_id DESC\nLIMIT 10;",
    "tokens_in": 361,
    "tokens_out": 61,
    "latency_ms": 753,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_02",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nORDER BY timestamp DESC, event_id DESC\nLIMIT 10;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nORDER BY timestamp DESC, event_id DESC\nLIMIT 10;",
    "tokens_in": 361,
    "tokens_out": 61,
    "latency_ms": 512,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_03",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS events_in_march_2024\nFROM events\nWHERE timestamp >= toDateTime64('2024-03-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-04-01 00:00:00', 3, 'UTC');",
    "raw_response": "SELECT count() AS events_in_march_2024\nFROM events\nWHERE timestamp >= toDateTime64('2024-03-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-04-01 00:00:00', 3, 'UTC');",
    "tokens_in": 363,
    "tokens_out": 75,
    "latency_ms": 1725,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_03",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS events_count\nFROM events\nWHERE timestamp >= toDateTime64('2024-03-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-04-01 00:00:00', 3, 'UTC');",
    "raw_response": "SELECT count() AS events_count\nFROM events\nWHERE timestamp >= toDateTime64('2024-03-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-04-01 00:00:00', 3, 'UTC');",
    "tokens_in": 363,
    "tokens_out": 70,
    "latency_ms": 604,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_03",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS events_in_march_2024\nFROM events\nWHERE timestamp >= toDateTime64('2024-03-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-04-01 00:00:00', 3, 'UTC');",
    "raw_response": "SELECT count() AS events_in_march_2024\nFROM events\nWHERE timestamp >= toDateTime64('2024-03-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-04-01 00:00:00', 3, 'UTC');",
    "tokens_in": 363,
    "tokens_out": 75,
    "latency_ms": 704,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_04",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT DISTINCT event_type\nFROM events\nORDER BY event_type;",
    "raw_response": "SELECT DISTINCT event_type\nFROM events\nORDER BY event_type;",
    "tokens_in": 359,
    "tokens_out": 17,
    "latency_ms": 593,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_04",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT DISTINCT event_type\nFROM events;",
    "raw_response": "SELECT DISTINCT event_type\nFROM events;",
    "tokens_in": 359,
    "tokens_out": 12,
    "latency_ms": 564,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_04",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT DISTINCT event_type\nFROM events\nORDER BY event_type;",
    "raw_response": "SELECT DISTINCT event_type\nFROM events\nORDER BY event_type;",
    "tokens_in": 359,
    "tokens_out": 17,
    "latency_ms": 521,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_05",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS events_from_germany\nFROM events\nWHERE country = 'DE';",
    "raw_response": "SELECT count() AS events_from_germany\nFROM events\nWHERE country = 'DE';",
    "tokens_in": 360,
    "tokens_out": 22,
    "latency_ms": 576,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_05",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS events_from_germany\nFROM events\nWHERE country = 'DE';",
    "raw_response": "SELECT count() AS events_from_germany\nFROM events\nWHERE country = 'DE';",
    "tokens_in": 360,
    "tokens_out": 22,
    "latency_ms": 546,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_05",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS events_from_germany\nFROM events\nWHERE country = 'DE';",
    "raw_response": "SELECT count() AS events_from_germany\nFROM events\nWHERE country = 'DE';",
    "tokens_in": 360,
    "tokens_out": 22,
    "latency_ms": 570,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_06",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC\nLIMIT 5;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC\nLIMIT 5;",
    "tokens_in": 368,
    "tokens_out": 64,
    "latency_ms": 521,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_06",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC\nLIMIT 5;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC\nLIMIT 5;",
    "tokens_in": 368,
    "tokens_out": 64,
    "latency_ms": 541,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_06",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC\nLIMIT 5;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC\nLIMIT 5;",
    "tokens_in": 368,
    "tokens_out": 64,
    "latency_ms": 487,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_07",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS pro_users\nFROM users\nWHERE plan = 'pro';",
    "raw_response": "SELECT count() AS pro_users\nFROM users\nWHERE plan = 'pro';",
    "tokens_in": 364,
    "tokens_out": 20,
    "latency_ms": 506,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_07",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS pro_users\nFROM users\nWHERE plan = 'pro';",
    "raw_response": "SELECT count() AS pro_users\nFROM users\nWHERE plan = 'pro';",
    "tokens_in": 364,
    "tokens_out": 20,
    "latency_ms": 542,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_07",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS pro_users\nFROM users\nWHERE plan = 'pro';",
    "raw_response": "SELECT count() AS pro_users\nFROM users\nWHERE plan = 'pro';",
    "tokens_in": 364,
    "tokens_out": 20,
    "latency_ms": 603,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_08",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    min(timestamp) AS earliest_event_timestamp,\n    max(timestamp) AS latest_event_timestamp\nFROM events;",
    "raw_response": "SELECT\n    min(timestamp) AS earliest_event_timestamp,\n    max(timestamp) AS latest_event_timestamp\nFROM events;",
    "tokens_in": 362,
    "tokens_out": 27,
    "latency_ms": 552,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_08",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    min(timestamp) AS earliest_event_timestamp,\n    max(timestamp) AS latest_event_timestamp\nFROM events;",
    "raw_response": "SELECT\n    min(timestamp) AS earliest_event_timestamp,\n    max(timestamp) AS latest_event_timestamp\nFROM events;",
    "tokens_in": 362,
    "tokens_out": 27,
    "latency_ms": 685,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_08",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    min(timestamp) AS earliest_event_timestamp,\n    max(timestamp) AS latest_event_timestamp\nFROM events;",
    "raw_response": "SELECT\n    min(timestamp) AS earliest_event_timestamp,\n    max(timestamp) AS latest_event_timestamp\nFROM events;",
    "tokens_in": 362,
    "tokens_out": 27,
    "latency_ms": 505,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_09",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE\n    user_id = 42\n    AND timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n    AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nORDER BY timestamp, event_id;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE\n    user_id = 42\n    AND timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n    AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nORDER BY timestamp, event_id;",
    "tokens_in": 366,
    "tokens_out": 121,
    "latency_ms": 517,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_09",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE user_id = 42\n  AND timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nORDER BY timestamp, event_id;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE user_id = 42\n  AND timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nORDER BY timestamp, event_id;",
    "tokens_in": 366,
    "tokens_out": 119,
    "latency_ms": 584,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_09",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE user_id = 42\n  AND timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nORDER BY timestamp, event_id;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE user_id = 42\n  AND timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nORDER BY timestamp, event_id;",
    "tokens_in": 366,
    "tokens_out": 119,
    "latency_ms": 640,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_10",
    "run": 1,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count()\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "raw_response": "SELECT count()\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "tokens_in": 363,
    "tokens_out": 17,
    "latency_ms": 593,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_10",
    "run": 2,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count() AS events_with_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "raw_response": "SELECT count() AS events_with_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "tokens_in": 363,
    "tokens_out": 23,
    "latency_ms": 540,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t1_10",
    "run": 3,
    "tier": 1,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT count()\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "raw_response": "SELECT count()\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "tokens_in": 363,
    "tokens_out": 17,
    "latency_ms": 549,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_01",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    count() AS event_count\nFROM events\nGROUP BY event_type\nORDER BY event_count DESC;",
    "raw_response": "SELECT\n    event_type,\n    count() AS event_count\nFROM events\nGROUP BY event_type\nORDER BY event_count DESC;",
    "tokens_in": 365,
    "tokens_out": 31,
    "latency_ms": 596,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_01",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    count() AS events_count\nFROM events\nGROUP BY event_type\nORDER BY events_count DESC;",
    "raw_response": "SELECT\n    event_type,\n    count() AS events_count\nFROM events\nGROUP BY event_type\nORDER BY events_count DESC;",
    "tokens_in": 365,
    "tokens_out": 31,
    "latency_ms": 555,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_01",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    count() AS event_count\nFROM events\nGROUP BY event_type\nORDER BY event_count DESC;",
    "raw_response": "SELECT\n    event_type,\n    count() AS event_count\nFROM events\nGROUP BY event_type\nORDER BY event_count DESC;",
    "tokens_in": 365,
    "tokens_out": 31,
    "latency_ms": 681,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_02",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    device,\n    avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL\nGROUP BY device\nORDER BY device;",
    "raw_response": "SELECT\n    device,\n    avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL\nGROUP BY device\nORDER BY device;",
    "tokens_in": 363,
    "tokens_out": 37,
    "latency_ms": 638,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_02",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    device,\n    avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL\nGROUP BY device\nORDER BY device;",
    "raw_response": "SELECT\n    device,\n    avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL\nGROUP BY device\nORDER BY device;",
    "tokens_in": 363,
    "tokens_out": 37,
    "latency_ms": 567,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_02",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    device,\n    avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL\nGROUP BY device\nORDER BY device;",
    "raw_response": "SELECT\n    device,\n    avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL\nGROUP BY device\nORDER BY device;",
    "tokens_in": 363,
    "tokens_out": 37,
    "latency_ms": 546,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_03",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toDate(timestamp) AS day,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-02-01 00:00:00', 3, 'UTC')\nGROUP BY day\nORDER BY day;",
    "raw_response": "SELECT\n    toDate(timestamp) AS day,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-02-01 00:00:00', 3, 'UTC')\nGROUP BY day\nORDER BY day;",
    "tokens_in": 366,
    "tokens_out": 87,
    "latency_ms": 546,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_03",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toDate(timestamp) AS day,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime('2024-01-01 00:00:00', 'UTC')\n  AND timestamp <  toDateTime('2024-02-01 00:00:00', 'UTC')\nGROUP BY day\nORDER BY day;",
    "raw_response": "SELECT\n    toDate(timestamp) AS day,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime('2024-01-01 00:00:00', 'UTC')\n  AND timestamp <  toDateTime('2024-02-01 00:00:00', 'UTC')\nGROUP BY day\nORDER BY day;",
    "tokens_in": 366,
    "tokens_out": 79,
    "latency_ms": 513,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_03",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toDate(timestamp) AS day,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime('2024-01-01 00:00:00', 'UTC')\n  AND timestamp <  toDateTime('2024-02-01 00:00:00', 'UTC')\nGROUP BY day\nORDER BY day;",
    "raw_response": "SELECT\n    toDate(timestamp) AS day,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime('2024-01-01 00:00:00', 'UTC')\n  AND timestamp <  toDateTime('2024-02-01 00:00:00', 'UTC')\nGROUP BY day\nORDER BY day;",
    "tokens_in": 366,
    "tokens_out": 79,
    "latency_ms": 570,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_04",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    country,\n    count() AS event_count\nFROM events\nGROUP BY country\nHAVING event_count > 10000\nORDER BY event_count DESC;",
    "raw_response": "SELECT\n    country,\n    count() AS event_count\nFROM events\nGROUP BY country\nHAVING event_count > 10000\nORDER BY event_count DESC;",
    "tokens_in": 363,
    "tokens_out": 38,
    "latency_ms": 559,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_04",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    country,\n    count() AS event_count\nFROM events\nGROUP BY country\nHAVING event_count > 10000\nORDER BY event_count DESC;",
    "raw_response": "SELECT\n    country,\n    count() AS event_count\nFROM events\nGROUP BY country\nHAVING event_count > 10000\nORDER BY event_count DESC;",
    "tokens_in": 363,
    "tokens_out": 38,
    "latency_ms": 535,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_04",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    country,\n    count() AS event_count\nFROM events\nGROUP BY country\nHAVING event_count > 10000\nORDER BY event_count DESC;",
    "raw_response": "SELECT\n    country,\n    count() AS event_count\nFROM events\nGROUP BY country\nHAVING event_count > 10000\nORDER BY event_count DESC;",
    "tokens_in": 363,
    "tokens_out": 38,
    "latency_ms": 511,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_05",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toHour(timestamp) AS hour_of_day,\n    count() AS events\nFROM events\nGROUP BY hour_of_day\nORDER BY hour_of_day;",
    "raw_response": "SELECT\n    toHour(timestamp) AS hour_of_day,\n    count() AS events\nFROM events\nGROUP BY hour_of_day\nORDER BY hour_of_day;",
    "tokens_in": 364,
    "tokens_out": 37,
    "latency_ms": 553,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_05",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toHour(timestamp) AS hour_of_day,\n    count() AS event_count\nFROM events\nGROUP BY hour_of_day\nORDER BY hour_of_day;",
    "raw_response": "SELECT\n    toHour(timestamp) AS hour_of_day,\n    count() AS event_count\nFROM events\nGROUP BY hour_of_day\nORDER BY hour_of_day;",
    "tokens_in": 364,
    "tokens_out": 38,
    "latency_ms": 590,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_05",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toHour(timestamp) AS hour_of_day,\n    count() AS event_count\nFROM events\nGROUP BY hour_of_day\nORDER BY hour_of_day;",
    "raw_response": "SELECT\n    toHour(timestamp) AS hour_of_day,\n    count() AS event_count\nFROM events\nGROUP BY hour_of_day\nORDER BY hour_of_day;",
    "tokens_in": 364,
    "tokens_out": 38,
    "latency_ms": 527,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_06",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE event_type = 'pageview';",
    "raw_response": "SELECT avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE event_type = 'pageview';",
    "tokens_in": 367,
    "tokens_out": 25,
    "latency_ms": 489,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_06",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE event_type = 'pageview';",
    "raw_response": "SELECT avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE event_type = 'pageview';",
    "tokens_in": 367,
    "tokens_out": 25,
    "latency_ms": 558,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_06",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE event_type = 'pageview';",
    "raw_response": "SELECT avg(duration_ms) AS avg_duration_ms\nFROM events\nWHERE event_type = 'pageview';",
    "tokens_in": 367,
    "tokens_out": 25,
    "latency_ms": 1210,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_07",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toStartOfMonth(timestamp) AS month,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nGROUP BY month\nORDER BY month;",
    "raw_response": "SELECT\n    toStartOfMonth(timestamp) AS month,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nGROUP BY month\nORDER BY month;",
    "tokens_in": 363,
    "tokens_out": 89,
    "latency_ms": 517,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_07",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toStartOfMonth(timestamp) AS month,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nGROUP BY month\nORDER BY month;",
    "raw_response": "SELECT\n    toStartOfMonth(timestamp) AS month,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nGROUP BY month\nORDER BY month;",
    "tokens_in": 363,
    "tokens_out": 89,
    "latency_ms": 564,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_07",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    toStartOfMonth(timestamp) AS month,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nGROUP BY month\nORDER BY month;",
    "raw_response": "SELECT\n    toStartOfMonth(timestamp) AS month,\n    count() AS events\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\nGROUP BY month\nORDER BY month;",
    "tokens_in": 363,
    "tokens_out": 89,
    "latency_ms": 516,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_08",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    uniqExact(country) AS distinct_countries\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    uniqExact(country) AS distinct_countries\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "tokens_in": 365,
    "tokens_out": 33,
    "latency_ms": 526,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_08",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    uniqExact(country) AS distinct_countries\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    uniqExact(country) AS distinct_countries\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "tokens_in": 365,
    "tokens_out": 33,
    "latency_ms": 641,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_08",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    countDistinct(country) AS distinct_countries\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    countDistinct(country) AS distinct_countries\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "tokens_in": 365,
    "tokens_out": 33,
    "latency_ms": 607,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_09",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    country,\n    sum(revenue_cents) AS total_revenue_cents\nFROM events\nWHERE revenue_cents IS NOT NULL\nGROUP BY country\nORDER BY total_revenue_cents DESC;",
    "raw_response": "SELECT\n    country,\n    sum(revenue_cents) AS total_revenue_cents\nFROM events\nWHERE revenue_cents IS NOT NULL\nGROUP BY country\nORDER BY total_revenue_cents DESC;",
    "tokens_in": 367,
    "tokens_out": 47,
    "latency_ms": 545,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_09",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    country,\n    sum(revenue_cents) AS total_revenue_cents\nFROM events\nWHERE revenue_cents IS NOT NULL\nGROUP BY country\nORDER BY total_revenue_cents DESC;",
    "raw_response": "SELECT\n    country,\n    sum(revenue_cents) AS total_revenue_cents\nFROM events\nWHERE revenue_cents IS NOT NULL\nGROUP BY country\nORDER BY total_revenue_cents DESC;",
    "tokens_in": 367,
    "tokens_out": 47,
    "latency_ms": 542,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_09",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    country,\n    sum(revenue_cents) AS total_revenue_cents\nFROM events\nWHERE revenue_cents IS NOT NULL\nGROUP BY country\nORDER BY total_revenue_cents DESC;",
    "raw_response": "SELECT\n    country,\n    sum(revenue_cents) AS total_revenue_cents\nFROM events\nWHERE revenue_cents IS NOT NULL\nGROUP BY country\nORDER BY total_revenue_cents DESC;",
    "tokens_in": 367,
    "tokens_out": 47,
    "latency_ms": 530,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_10",
    "run": 1,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    count() AS event_count\nFROM events\nWHERE event_type IN ('purchase', 'pageview')\nGROUP BY event_type\nORDER BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    count() AS event_count\nFROM events\nWHERE event_type IN ('purchase', 'pageview')\nGROUP BY event_type\nORDER BY event_type;",
    "tokens_in": 367,
    "tokens_out": 41,
    "latency_ms": 536,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_10",
    "run": 2,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    countIf(event_type = 'purchase') AS purchase_events,\n    countIf(event_type = 'pageview') AS pageview_events\nFROM events;",
    "raw_response": "SELECT\n    countIf(event_type = 'purchase') AS purchase_events,\n    countIf(event_type = 'pageview') AS pageview_events\nFROM events;",
    "tokens_in": 367,
    "tokens_out": 37,
    "latency_ms": 563,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t2_10",
    "run": 3,
    "tier": 2,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    count() AS event_count\nFROM events\nWHERE event_type IN ('purchase', 'pageview')\nGROUP BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    count() AS event_count\nFROM events\nWHERE event_type IN ('purchase', 'pageview')\nGROUP BY event_type;",
    "tokens_in": 367,
    "tokens_out": 36,
    "latency_ms": 596,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_01",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT medianExactIf(toFloat64(duration_ms), duration_ms IS NOT NULL) AS median_duration_ms\nFROM events;",
    "raw_response": "SELECT medianExactIf(toFloat64(duration_ms), duration_ms IS NOT NULL) AS median_duration_ms\nFROM events;",
    "tokens_in": 363,
    "tokens_out": 28,
    "latency_ms": 557,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_01",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT medianExact(duration_ms) AS median_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "raw_response": "SELECT medianExact(duration_ms) AS median_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "tokens_in": 363,
    "tokens_out": 25,
    "latency_ms": 553,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_01",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT quantileExact(0.5)(duration_ms) AS median_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "raw_response": "SELECT quantileExact(0.5)(duration_ms) AS median_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL;",
    "tokens_in": 363,
    "tokens_out": 31,
    "latency_ms": 559,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_02",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT countDistinct(user_id) AS exact_distinct_users\nFROM events;",
    "raw_response": "SELECT countDistinct(user_id) AS exact_distinct_users\nFROM events;",
    "tokens_in": 365,
    "tokens_out": 19,
    "latency_ms": 536,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_02",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT uniqExact(user_id) AS exact_distinct_users\nFROM events;",
    "raw_response": "SELECT uniqExact(user_id) AS exact_distinct_users\nFROM events;",
    "tokens_in": 365,
    "tokens_out": 19,
    "latency_ms": 542,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_02",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT countDistinct(user_id) AS exact_distinct_users\nFROM events;",
    "raw_response": "SELECT countDistinct(user_id) AS exact_distinct_users\nFROM events;",
    "tokens_in": 365,
    "tokens_out": 19,
    "latency_ms": 533,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_03",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE mapContains(properties, 'campaign');",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE mapContains(properties, 'campaign');",
    "tokens_in": 366,
    "tokens_out": 56,
    "latency_ms": 644,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_03",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE mapContains(properties, 'campaign');",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE mapContains(properties, 'campaign');",
    "tokens_in": 366,
    "tokens_out": 56,
    "latency_ms": 525,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_03",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE mapContains(properties, 'campaign');",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE mapContains(properties, 'campaign');",
    "tokens_in": 366,
    "tokens_out": 56,
    "latency_ms": 851,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_04",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT properties['source'] AS source\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC, event_id ASC\nLIMIT 10;",
    "raw_response": "SELECT properties['source'] AS source\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC, event_id ASC\nLIMIT 10;",
    "tokens_in": 374,
    "tokens_out": 35,
    "latency_ms": 753,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_04",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT properties['source'] AS source\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp, event_id\nLIMIT 10;",
    "raw_response": "SELECT properties['source'] AS source\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp, event_id\nLIMIT 10;",
    "tokens_in": 374,
    "tokens_out": 33,
    "latency_ms": 606,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_04",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT properties['source'] AS source\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC, event_id ASC\nLIMIT 10;",
    "raw_response": "SELECT properties['source'] AS source\nFROM events\nWHERE event_type = 'purchase'\nORDER BY timestamp ASC, event_id ASC\nLIMIT 10;",
    "tokens_in": 374,
    "tokens_out": 35,
    "latency_ms": 686,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_05",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    tag,\n    count() AS occurrences\nFROM events\nARRAY JOIN tags AS tag\nGROUP BY tag\nORDER BY occurrences DESC, tag ASC;",
    "raw_response": "SELECT\n    tag,\n    count() AS occurrences\nFROM events\nARRAY JOIN tags AS tag\nGROUP BY tag\nORDER BY occurrences DESC, tag ASC;",
    "tokens_in": 373,
    "tokens_out": 36,
    "latency_ms": 508,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_05",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    tag,\n    count() AS occurrences\nFROM events\nARRAY JOIN tags AS tag\nGROUP BY tag\nORDER BY occurrences DESC, tag ASC;",
    "raw_response": "SELECT\n    tag,\n    count() AS occurrences\nFROM events\nARRAY JOIN tags AS tag\nGROUP BY tag\nORDER BY occurrences DESC, tag ASC;",
    "tokens_in": 373,
    "tokens_out": 36,
    "latency_ms": 539,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_05",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    tag,\n    count() AS occurrences\nFROM events\nARRAY JOIN tags AS tag\nGROUP BY tag\nORDER BY occurrences DESC, tag ASC;",
    "raw_response": "SELECT\n    tag,\n    count() AS occurrences\nFROM events\nARRAY JOIN tags AS tag\nGROUP BY tag\nORDER BY occurrences DESC, tag ASC;",
    "tokens_in": 373,
    "tokens_out": 36,
    "latency_ms": 636,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_06",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    *\nFROM events\nWHERE has(tags, 'promo');",
    "raw_response": "SELECT\n    *\nFROM events\nWHERE has(tags, 'promo');",
    "tokens_in": 367,
    "tokens_out": 18,
    "latency_ms": 506,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_06",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE has(tags, 'promo');",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE has(tags, 'promo');",
    "tokens_in": 367,
    "tokens_out": 55,
    "latency_ms": 548,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_06",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE has(tags, 'promo');",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE has(tags, 'promo');",
    "tokens_in": 367,
    "tokens_out": 55,
    "latency_ms": 560,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_07",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    quantileExactIf(0.90)(duration_ms, duration_ms IS NOT NULL) AS p90_duration_ms,\n    quantileExactIf(0.99)(duration_ms, duration_ms IS NOT NULL) AS p99_duration_ms\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    quantileExactIf(0.90)(duration_ms, duration_ms IS NOT NULL) AS p90_duration_ms,\n    quantileExactIf(0.99)(duration_ms, duration_ms IS NOT NULL) AS p99_duration_ms\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "tokens_in": 369,
    "tokens_out": 73,
    "latency_ms": 324,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_07",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    quantileTDigest(0.90)(toFloat64(duration_ms)) AS p90_duration_ms,\n    quantileTDigest(0.99)(toFloat64(duration_ms)) AS p99_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL\nGROUP BY event_type\nORDER BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    quantileTDigest(0.90)(toFloat64(duration_ms)) AS p90_duration_ms,\n    quantileTDigest(0.99)(toFloat64(duration_ms)) AS p99_duration_ms\nFROM events\nWHERE duration_ms IS NOT NULL\nGROUP BY event_type\nORDER BY event_type;",
    "tokens_in": 369,
    "tokens_out": 74,
    "latency_ms": 612,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_07",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    quantileExactIf(0.90)(duration_ms, duration_ms IS NOT NULL) AS p90_duration_ms,\n    quantileExactIf(0.99)(duration_ms, duration_ms IS NOT NULL) AS p99_duration_ms\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    quantileExactIf(0.90)(duration_ms, duration_ms IS NOT NULL) AS p90_duration_ms,\n    quantileExactIf(0.99)(duration_ms, duration_ms IS NOT NULL) AS p99_duration_ms\nFROM events\nGROUP BY event_type\nORDER BY event_type;",
    "tokens_in": 369,
    "tokens_out": 73,
    "latency_ms": 627,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_08",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT sumIf(revenue_cents, device = 'mobile') AS revenue_cents_mobile\nFROM events;",
    "raw_response": "SELECT sumIf(revenue_cents, device = 'mobile') AS revenue_cents_mobile\nFROM events;",
    "tokens_in": 370,
    "tokens_out": 26,
    "latency_ms": 564,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_08",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT sumIf(revenue_cents, device = 'mobile') AS mobile_revenue_cents\nFROM events;",
    "raw_response": "SELECT sumIf(revenue_cents, device = 'mobile') AS mobile_revenue_cents\nFROM events;",
    "tokens_in": 370,
    "tokens_out": 27,
    "latency_ms": 1423,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_08",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    sumIf(revenue_cents, device = 'mobile') AS revenue_cents_mobile\nFROM events;",
    "raw_response": "SELECT\n    sumIf(revenue_cents, device = 'mobile') AS revenue_cents_mobile\nFROM events;",
    "tokens_in": 370,
    "tokens_out": 28,
    "latency_ms": 643,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_09",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT DISTINCT mapKeys(properties) AS property_key\nFROM events\nARRAY JOIN mapKeys(properties) AS property_key\nORDER BY property_key;",
    "raw_response": "SELECT DISTINCT mapKeys(properties) AS property_key\nFROM events\nARRAY JOIN mapKeys(properties) AS property_key\nORDER BY property_key;",
    "tokens_in": 367,
    "tokens_out": 32,
    "latency_ms": 571,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_09",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT DISTINCT mapKeys(properties) AS property_key\nFROM events\nARRAY JOIN mapKeys(properties)\nORDER BY property_key;",
    "raw_response": "SELECT DISTINCT mapKeys(properties) AS property_key\nFROM events\nARRAY JOIN mapKeys(properties)\nORDER BY property_key;",
    "tokens_in": 367,
    "tokens_out": 28,
    "latency_ms": 539,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_09",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT arrayJoin(mapKeys(properties)) AS property_key\nFROM events\nGROUP BY property_key\nORDER BY property_key ASC;",
    "raw_response": "SELECT arrayJoin(mapKeys(properties)) AS property_key\nFROM events\nGROUP BY property_key\nORDER BY property_key ASC;",
    "tokens_in": 367,
    "tokens_out": 29,
    "latency_ms": 512,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_10",
    "run": 1,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    *\nFROM events\nWHERE arrayExists(tag -> startsWith(tag, 'vip'), tags);",
    "raw_response": "SELECT\n    *\nFROM events\nWHERE arrayExists(tag -> startsWith(tag, 'vip'), tags);",
    "tokens_in": 371,
    "tokens_out": 25,
    "latency_ms": 534,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_10",
    "run": 2,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    *\nFROM events\nWHERE arrayExists(t -> startsWith(t, 'vip'), tags);",
    "raw_response": "SELECT\n    *\nFROM events\nWHERE arrayExists(t -> startsWith(t, 'vip'), tags);",
    "tokens_in": 371,
    "tokens_out": 25,
    "latency_ms": 520,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t3_10",
    "run": 3,
    "tier": 3,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    *\nFROM events\nWHERE arrayExists(t -> startsWith(t, 'vip'), tags);",
    "raw_response": "SELECT\n    *\nFROM events\nWHERE arrayExists(t -> startsWith(t, 'vip'), tags);",
    "tokens_in": 371,
    "tokens_out": 25,
    "latency_ms": 536,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_01",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents,\n    u.plan AS user_plan\nFROM events AS e\nLEFT JOIN users AS u\n    ON e.user_id = u.user_id;",
    "raw_response": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents,\n    u.plan AS user_plan\nFROM events AS e\nLEFT JOIN users AS u\n    ON e.user_id = u.user_id;",
    "tokens_in": 371,
    "tokens_out": 85,
    "latency_ms": 522,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_01",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents,\n    u.plan\nFROM events AS e\nINNER JOIN users AS u\n    ON e.user_id = u.user_id;",
    "raw_response": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents,\n    u.plan\nFROM events AS e\nINNER JOIN users AS u\n    ON e.user_id = u.user_id;",
    "tokens_in": 371,
    "tokens_out": 82,
    "latency_ms": 549,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_01",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents,\n    u.plan\nFROM events AS e\nLEFT JOIN users AS u\n    ON e.user_id = u.user_id;",
    "raw_response": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents,\n    u.plan\nFROM events AS e\nLEFT JOIN users AS u\n    ON e.user_id = u.user_id;",
    "tokens_in": 371,
    "tokens_out": 82,
    "latency_ms": 523,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_02",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.plan,\n    count() AS events_count\nFROM events AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY events_count DESC;",
    "raw_response": "SELECT\n    u.plan,\n    count() AS events_count\nFROM events AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY events_count DESC;",
    "tokens_in": 360,
    "tokens_out": 47,
    "latency_ms": 534,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_02",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.plan,\n    count() AS event_count\nFROM events AS e\nINNER JOIN users AS u ON e.user_id = u.user_id\nGROUP BY u.plan\nORDER BY event_count DESC;",
    "raw_response": "SELECT\n    u.plan,\n    count() AS event_count\nFROM events AS e\nINNER JOIN users AS u ON e.user_id = u.user_id\nGROUP BY u.plan\nORDER BY event_count DESC;",
    "tokens_in": 360,
    "tokens_out": 47,
    "latency_ms": 528,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_02",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.plan,\n    count() AS event_count\nFROM events AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY event_count DESC;",
    "raw_response": "SELECT\n    u.plan,\n    count() AS event_count\nFROM events AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY event_count DESC;",
    "tokens_in": 360,
    "tokens_out": 47,
    "latency_ms": 597,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_03",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT u.user_id\nFROM users AS u\nLEFT JOIN\n(\n    SELECT DISTINCT user_id\n    FROM events\n) AS e USING (user_id)\nWHERE e.user_id IS NULL;",
    "raw_response": "SELECT u.user_id\nFROM users AS u\nLEFT JOIN\n(\n    SELECT DISTINCT user_id\n    FROM events\n) AS e USING (user_id)\nWHERE e.user_id IS NULL;",
    "tokens_in": 362,
    "tokens_out": 43,
    "latency_ms": 598,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_03",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT u.user_id\nFROM users AS u\nLEFT JOIN\n(\n    SELECT DISTINCT user_id\n    FROM events\n) AS e USING (user_id)\nWHERE e.user_id IS NULL;",
    "raw_response": "SELECT u.user_id\nFROM users AS u\nLEFT JOIN\n(\n    SELECT DISTINCT user_id\n    FROM events\n) AS e USING (user_id)\nWHERE e.user_id IS NULL;",
    "tokens_in": 362,
    "tokens_out": 43,
    "latency_ms": 733,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_03",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT u.user_id\nFROM users AS u\nLEFT JOIN\n(\n    SELECT DISTINCT user_id\n    FROM events\n) AS e\nON u.user_id = e.user_id\nWHERE e.user_id IS NULL;",
    "raw_response": "SELECT u.user_id\nFROM users AS u\nLEFT JOIN\n(\n    SELECT DISTINCT user_id\n    FROM events\n) AS e\nON u.user_id = e.user_id\nWHERE e.user_id IS NULL;",
    "tokens_in": 362,
    "tokens_out": 48,
    "latency_ms": 575,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_04",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH top_users AS\n(\n    SELECT\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY user_id\n    ORDER BY event_count DESC\n    LIMIT 10\n)\nSELECT\n    tu.user_id,\n    tu.event_count,\n    u.plan\nFROM top_users AS tu\nLEFT JOIN users AS u USING (user_id)\nORDER BY tu.event_count DESC;",
    "raw_response": "WITH top_users AS\n(\n    SELECT\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY user_id\n    ORDER BY event_count DESC\n    LIMIT 10\n)\nSELECT\n    tu.user_id,\n    tu.event_count,\n    u.plan\nFROM top_users AS tu\nLEFT JOIN users AS u USING (user_id)\nORDER BY tu.event_count DESC;",
    "tokens_in": 373,
    "tokens_out": 86,
    "latency_ms": 532,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_04",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH top_users AS\n(\n    SELECT\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY user_id\n    ORDER BY event_count DESC\n    LIMIT 10\n)\nSELECT\n    tu.user_id,\n    tu.event_count,\n    u.plan\nFROM top_users AS tu\nLEFT JOIN users AS u USING (user_id)\nORDER BY tu.event_count DESC;",
    "raw_response": "WITH top_users AS\n(\n    SELECT\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY user_id\n    ORDER BY event_count DESC\n    LIMIT 10\n)\nSELECT\n    tu.user_id,\n    tu.event_count,\n    u.plan\nFROM top_users AS tu\nLEFT JOIN users AS u USING (user_id)\nORDER BY tu.event_count DESC;",
    "tokens_in": 373,
    "tokens_out": 86,
    "latency_ms": 547,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_04",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH top_users AS\n(\n    SELECT\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY user_id\n    ORDER BY event_count DESC\n    LIMIT 10\n)\nSELECT\n    t.user_id,\n    t.event_count,\n    u.plan\nFROM top_users AS t\nLEFT JOIN users AS u USING (user_id)\nORDER BY t.event_count DESC, t.user_id;",
    "raw_response": "WITH top_users AS\n(\n    SELECT\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY user_id\n    ORDER BY event_count DESC\n    LIMIT 10\n)\nSELECT\n    t.user_id,\n    t.event_count,\n    u.plan\nFROM top_users AS t\nLEFT JOIN users AS u USING (user_id)\nORDER BY t.event_count DESC, t.user_id;",
    "tokens_in": 373,
    "tokens_out": 90,
    "latency_ms": 603,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_05",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    event_count\nFROM\n(\n    SELECT\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY user_id\n)\nWHERE event_count > (\n    SELECT avg(event_count)\n    FROM\n    (\n        SELECT\n            user_id,\n            count() AS event_count\n        FROM events\n        GROUP BY user_id\n    )\n)\nORDER BY event_count DESC;",
    "raw_response": "SELECT\n    user_id,\n    event_count\nFROM\n(\n    SELECT\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY user_id\n)\nWHERE event_count > (\n    SELECT avg(event_count)\n    FROM\n    (\n        SELECT\n            user_id,\n            count() AS event_count\n        FROM events\n        GROUP BY user_id\n    )\n)\nORDER BY event_count DESC;",
    "tokens_in": 368,
    "tokens_out": 91,
    "latency_ms": 598,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_05",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    count() AS total_events\nFROM events\nGROUP BY user_id\nHAVING total_events > (\n    SELECT avg(event_count)\n    FROM\n    (\n        SELECT\n            user_id,\n            count() AS event_count\n        FROM events\n        GROUP BY user_id\n    )\n);",
    "raw_response": "SELECT\n    user_id,\n    count() AS total_events\nFROM events\nGROUP BY user_id\nHAVING total_events > (\n    SELECT avg(event_count)\n    FROM\n    (\n        SELECT\n            user_id,\n            count() AS event_count\n        FROM events\n        GROUP BY user_id\n    )\n);",
    "tokens_in": 372,
    "tokens_out": 65,
    "latency_ms": 546,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_05",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    count() AS total_event_count\nFROM events\nGROUP BY user_id\nHAVING total_event_count > (\n    SELECT avg(event_count)\n    FROM\n    (\n        SELECT\n            user_id,\n            count() AS event_count\n        FROM events\n        GROUP BY user_id\n    )\n);",
    "raw_response": "SELECT\n    user_id,\n    count() AS total_event_count\nFROM events\nGROUP BY user_id\nHAVING total_event_count > (\n    SELECT avg(event_count)\n    FROM\n    (\n        SELECT\n            user_id,\n            count() AS event_count\n        FROM events\n        GROUP BY user_id\n    )\n);",
    "tokens_in": 368,
    "tokens_out": 71,
    "latency_ms": 570,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_06",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE user_id IN (\n    SELECT user_id\n    FROM users\n    WHERE plan = 'enterprise'\n);",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents\nFROM events\nWHERE user_id IN (\n    SELECT user_id\n    FROM users\n    WHERE plan = 'enterprise'\n);",
    "tokens_in": 371,
    "tokens_out": 70,
    "latency_ms": 507,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_06",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents\nFROM events AS e\nWHERE e.user_id IN\n(\n    SELECT u.user_id\n    FROM users AS u\n    WHERE u.plan = 'enterprise'\n);",
    "raw_response": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents\nFROM events AS e\nWHERE e.user_id IN\n(\n    SELECT u.user_id\n    FROM users AS u\n    WHERE u.plan = 'enterprise'\n);",
    "tokens_in": 371,
    "tokens_out": 90,
    "latency_ms": 500,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_06",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents\nFROM events AS e\nWHERE e.user_id IN\n(\n    SELECT u.user_id\n    FROM users AS u\n    WHERE u.plan = 'enterprise'\n);",
    "raw_response": "SELECT\n    e.event_id,\n    e.timestamp,\n    e.user_id,\n    e.event_type,\n    e.page,\n    e.duration_ms,\n    e.properties,\n    e.tags,\n    e.country,\n    e.device,\n    e.revenue_cents\nFROM events AS e\nWHERE e.user_id IN\n(\n    SELECT u.user_id\n    FROM users AS u\n    WHERE u.plan = 'enterprise'\n);",
    "tokens_in": 371,
    "tokens_out": 90,
    "latency_ms": 1200,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_07",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.plan,\n    avg(e.events_per_user) AS avg_events_per_user\nFROM\n(\n    SELECT\n        user_id,\n        count() AS events_per_user\n    FROM events\n    GROUP BY user_id\n) AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY u.plan;",
    "raw_response": "SELECT\n    u.plan,\n    avg(e.events_per_user) AS avg_events_per_user\nFROM\n(\n    SELECT\n        user_id,\n        count() AS events_per_user\n    FROM events\n    GROUP BY user_id\n) AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY u.plan;",
    "tokens_in": 367,
    "tokens_out": 79,
    "latency_ms": 690,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_07",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.plan,\n    avg(e.events_per_user) AS avg_events_per_user\nFROM\n(\n    SELECT\n        user_id,\n        count() AS events_per_user\n    FROM events\n    GROUP BY user_id\n) AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY u.plan;",
    "raw_response": "SELECT\n    u.plan,\n    avg(e.events_per_user) AS avg_events_per_user\nFROM\n(\n    SELECT\n        user_id,\n        count() AS events_per_user\n    FROM events\n    GROUP BY user_id\n) AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY u.plan;",
    "tokens_in": 367,
    "tokens_out": 79,
    "latency_ms": 546,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_07",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.plan,\n    avg(events_per_user) AS avg_events_per_user\nFROM\n(\n    SELECT\n        user_id,\n        count() AS events_per_user\n    FROM events\n    GROUP BY user_id\n) e\nINNER JOIN users u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY u.plan;",
    "raw_response": "SELECT\n    u.plan,\n    avg(events_per_user) AS avg_events_per_user\nFROM\n(\n    SELECT\n        user_id,\n        count() AS events_per_user\n    FROM events\n    GROUP BY user_id\n) e\nINNER JOIN users u ON u.user_id = e.user_id\nGROUP BY u.plan\nORDER BY u.plan;",
    "tokens_in": 367,
    "tokens_out": 76,
    "latency_ms": 604,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_08",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT DISTINCT e.user_id\nFROM events AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nWHERE u.created_at >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND u.created_at <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n  AND e.event_type = 'purchase';",
    "raw_response": "SELECT DISTINCT e.user_id\nFROM events AS e\nINNER JOIN users AS u ON u.user_id = e.user_id\nWHERE u.created_at >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND u.created_at <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n  AND e.event_type = 'purchase';",
    "tokens_in": 370,
    "tokens_out": 98,
    "latency_ms": 537,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_08",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.user_id,\n    u.created_at,\n    u.plan,\n    u.email,\n    u.country\nFROM users AS u\nWHERE u.created_at >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND u.created_at <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n  AND u.user_id IN (\n      SELECT DISTINCT user_id\n      FROM events\n      WHERE event_type = 'purchase'\n  );",
    "raw_response": "SELECT\n    u.user_id,\n    u.created_at,\n    u.plan,\n    u.email,\n    u.country\nFROM users AS u\nWHERE u.created_at >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND u.created_at <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n  AND u.user_id IN (\n      SELECT DISTINCT user_id\n      FROM events\n      WHERE event_type = 'purchase'\n  );",
    "tokens_in": 370,
    "tokens_out": 120,
    "latency_ms": 1286,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_08",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.user_id,\n    u.created_at AS signup_time,\n    u.plan,\n    u.email,\n    u.country\nFROM users AS u\nWHERE u.created_at >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND u.created_at <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n  AND EXISTS\n  (\n      SELECT 1\n      FROM events AS e\n      WHERE e.user_id = u.user_id\n        AND e.event_type = 'purchase'\n      LIMIT 1\n  );",
    "raw_response": "SELECT\n    u.user_id,\n    u.created_at AS signup_time,\n    u.plan,\n    u.email,\n    u.country\nFROM users AS u\nWHERE u.created_at >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND u.created_at <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n  AND EXISTS\n  (\n      SELECT 1\n      FROM events AS e\n      WHERE e.user_id = u.user_id\n        AND e.event_type = 'purchase'\n      LIMIT 1\n  );",
    "tokens_in": 370,
    "tokens_out": 139,
    "latency_ms": 611,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_09",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    country,\n    count() AS pro_users\nFROM users\nWHERE plan = 'pro'\nGROUP BY country\nORDER BY pro_users DESC\nLIMIT 1;",
    "raw_response": "SELECT\n    country,\n    count() AS pro_users\nFROM users\nWHERE plan = 'pro'\nGROUP BY country\nORDER BY pro_users DESC\nLIMIT 1;",
    "tokens_in": 367,
    "tokens_out": 39,
    "latency_ms": 626,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_09",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    u.country,\n    count() AS pro_users\nFROM users AS u\nWHERE u.plan = 'pro'\nGROUP BY u.country\nORDER BY pro_users DESC\nLIMIT 1;",
    "raw_response": "SELECT\n    u.country,\n    count() AS pro_users\nFROM users AS u\nWHERE u.plan = 'pro'\nGROUP BY u.country\nORDER BY pro_users DESC\nLIMIT 1;",
    "tokens_in": 367,
    "tokens_out": 44,
    "latency_ms": 588,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_09",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    country,\n    count() AS pro_users\nFROM users\nWHERE plan = 'pro'\nGROUP BY country\nORDER BY pro_users DESC\nLIMIT 1;",
    "raw_response": "SELECT\n    country,\n    count() AS pro_users\nFROM users\nWHERE plan = 'pro'\nGROUP BY country\nORDER BY pro_users DESC\nLIMIT 1;",
    "tokens_in": 367,
    "tokens_out": 39,
    "latency_ms": 541,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_10",
    "run": 1,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH counts AS\n(\n    SELECT\n        device,\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY\n        device,\n        user_id\n)\nSELECT\n    device,\n    user_id,\n    event_count\nFROM\n(\n    SELECT\n        device,\n        user_id,\n        event_count,\n        row_number() OVER (PARTITION BY device ORDER BY event_count DESC, user_id ASC) AS rn\n    FROM counts\n)\nWHERE rn = 1\nORDER BY device;",
    "raw_response": "WITH counts AS\n(\n    SELECT\n        device,\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY\n        device,\n        user_id\n)\nSELECT\n    device,\n    user_id,\n    event_count\nFROM\n(\n    SELECT\n        device,\n        user_id,\n        event_count,\n        row_number() OVER (PARTITION BY device ORDER BY event_count DESC, user_id ASC) AS rn\n    FROM counts\n)\nWHERE rn = 1\nORDER BY device;",
    "tokens_in": 366,
    "tokens_out": 110,
    "latency_ms": 553,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_10",
    "run": 2,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH counts AS\n(\n    SELECT\n        device,\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY\n        device,\n        user_id\n)\nSELECT\n    device,\n    argMax(user_id, event_count) AS user_id,\n    max(event_count) AS event_count\nFROM counts\nGROUP BY device\nORDER BY device;",
    "raw_response": "WITH counts AS\n(\n    SELECT\n        device,\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY\n        device,\n        user_id\n)\nSELECT\n    device,\n    argMax(user_id, event_count) AS user_id,\n    max(event_count) AS event_count\nFROM counts\nGROUP BY device\nORDER BY device;",
    "tokens_in": 366,
    "tokens_out": 229,
    "latency_ms": 505,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t4_10",
    "run": 3,
    "tier": 4,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH counts AS\n(\n    SELECT\n        device,\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY\n        device,\n        user_id\n)\nSELECT\n    device,\n    user_id,\n    event_count\nFROM\n(\n    SELECT\n        device,\n        user_id,\n        event_count,\n        row_number() OVER (PARTITION BY device ORDER BY event_count DESC, user_id ASC) AS rn\n    FROM counts\n)\nWHERE rn = 1\nORDER BY device;",
    "raw_response": "WITH counts AS\n(\n    SELECT\n        device,\n        user_id,\n        count() AS event_count\n    FROM events\n    GROUP BY\n        device,\n        user_id\n)\nSELECT\n    device,\n    user_id,\n    event_count\nFROM\n(\n    SELECT\n        device,\n        user_id,\n        event_count,\n        row_number() OVER (PARTITION BY device ORDER BY event_count DESC, user_id ASC) AS rn\n    FROM counts\n)\nWHERE rn = 1\nORDER BY device;",
    "tokens_in": 366,
    "tokens_out": 188,
    "latency_ms": 500,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_01",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents,\n    row_number() OVER (PARTITION BY user_id ORDER BY timestamp, event_id) AS event_seq\nFROM events;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents,\n    row_number() OVER (PARTITION BY user_id ORDER BY timestamp, event_id) AS event_seq\nFROM events;",
    "tokens_in": 369,
    "tokens_out": 70,
    "latency_ms": 680,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_01",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents,\n    row_number() OVER (PARTITION BY user_id ORDER BY timestamp, event_id) AS event_seq\nFROM events;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents,\n    row_number() OVER (PARTITION BY user_id ORDER BY timestamp, event_id) AS event_seq\nFROM events;",
    "tokens_in": 369,
    "tokens_out": 70,
    "latency_ms": 570,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_01",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents,\n    row_number() OVER (PARTITION BY user_id ORDER BY timestamp, event_id) AS event_number\nFROM events;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    tags,\n    country,\n    device,\n    revenue_cents,\n    row_number() OVER (PARTITION BY user_id ORDER BY timestamp, event_id) AS event_number\nFROM events;",
    "tokens_in": 369,
    "tokens_out": 70,
    "latency_ms": 537,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_02",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH daily AS\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS events_count\n    FROM events\n    WHERE timestamp >= toDateTime64('2024-01-01 00:00:00.000', 3, 'UTC')\n      AND timestamp <  toDateTime64('2025-01-01 00:00:00.000', 3, 'UTC')\n    GROUP BY day\n)\nSELECT\n    day,\n    events_count,\n    sum(events_count) OVER (ORDER BY day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total_events\nFROM daily\nORDER BY day;",
    "raw_response": "WITH daily AS\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS events_count\n    FROM events\n    WHERE timestamp >= toDateTime64('2024-01-01 00:00:00.000', 3, 'UTC')\n      AND timestamp <  toDateTime64('2025-01-01 00:00:00.000', 3, 'UTC')\n    GROUP BY day\n)\nSELECT\n    day,\n    events_count,\n    sum(events_count) OVER (ORDER BY day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total_events\nFROM daily\nORDER BY day;",
    "tokens_in": 366,
    "tokens_out": 143,
    "latency_ms": 663,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_02",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH daily AS\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS events_count\n    FROM events\n    WHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n      AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n    GROUP BY day\n)\nSELECT\n    day,\n    events_count,\n    sum(events_count) OVER (ORDER BY day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total_events\nFROM daily\nORDER BY day;",
    "raw_response": "WITH daily AS\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS events_count\n    FROM events\n    WHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n      AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n    GROUP BY day\n)\nSELECT\n    day,\n    events_count,\n    sum(events_count) OVER (ORDER BY day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total_events\nFROM daily\nORDER BY day;",
    "tokens_in": 366,
    "tokens_out": 139,
    "latency_ms": 539,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_02",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH daily AS\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS events_per_day\n    FROM events\n    WHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n      AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n    GROUP BY day\n),\ncalendar AS\n(\n    SELECT\n        day\n    FROM\n    (\n        SELECT\n            arrayJoin(\n                arrayMap(\n                    i -> toDate('2024-01-01') + toIntervalDay(i),\n                    range(dateDiff('day', toDate('2024-01-01'), toDate('2025-01-01')))\n                )\n            ) AS day\n    )\n)\nSELECT\n    c.day,\n    coalesce(d.events_per_day, 0) AS events_per_day,\n    sum(coalesce(d.events_per_day, 0)) OVER (ORDER BY c.day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total_events\nFROM calendar AS c\nLEFT JOIN daily AS d USING (day)\nORDER BY c.day;",
    "raw_response": "WITH daily AS\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS events_per_day\n    FROM events\n    WHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n      AND timestamp <  toDateTime64('2025-01-01 00:00:00', 3, 'UTC')\n    GROUP BY day\n),\ncalendar AS\n(\n    SELECT\n        day\n    FROM\n    (\n        SELECT\n            arrayJoin(\n                arrayMap(\n                    i -> toDate('2024-01-01') + toIntervalDay(i),\n                    range(dateDiff('day', toDate('2024-01-01'), toDate('2025-01-01')))\n                )\n            ) AS day\n    )\n)\nSELECT\n    c.day,\n    coalesce(d.events_per_day, 0) AS events_per_day,\n    sum(coalesce(d.events_per_day, 0)) OVER (ORDER BY c.day ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total_events\nFROM calendar AS c\nLEFT JOIN daily AS d USING (day)\nORDER BY c.day;",
    "tokens_in": 366,
    "tokens_out": 255,
    "latency_ms": 541,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_03",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    day,\n    event_count,\n    lagInFrame(event_count, 1) OVER (ORDER BY day) AS prev_day_event_count\nFROM\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS event_count\n    FROM events\n    GROUP BY day\n)\nORDER BY day;",
    "raw_response": "SELECT\n    day,\n    event_count,\n    lagInFrame(event_count, 1) OVER (ORDER BY day) AS prev_day_event_count\nFROM\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS event_count\n    FROM events\n    GROUP BY day\n)\nORDER BY day;",
    "tokens_in": 371,
    "tokens_out": 70,
    "latency_ms": 588,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_03",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    day,\n    event_count,\n    lagInFrame(event_count, 1) OVER (ORDER BY day) AS prev_day_event_count\nFROM\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS event_count\n    FROM events\n    GROUP BY day\n)\nORDER BY day;",
    "raw_response": "SELECT\n    day,\n    event_count,\n    lagInFrame(event_count, 1) OVER (ORDER BY day) AS prev_day_event_count\nFROM\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS event_count\n    FROM events\n    GROUP BY day\n)\nORDER BY day;",
    "tokens_in": 371,
    "tokens_out": 70,
    "latency_ms": 640,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_03",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    day,\n    event_count,\n    lagInFrame(event_count, 1) OVER (ORDER BY day) AS prev_day_event_count\nFROM\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS event_count\n    FROM events\n    GROUP BY day\n)\nORDER BY day;",
    "raw_response": "SELECT\n    day,\n    event_count,\n    lagInFrame(event_count, 1) OVER (ORDER BY day) AS prev_day_event_count\nFROM\n(\n    SELECT\n        toDate(timestamp) AS day,\n        count() AS event_count\n    FROM events\n    GROUP BY day\n)\nORDER BY day;",
    "tokens_in": 371,
    "tokens_out": 70,
    "latency_ms": 649,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_04",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    arrayMap(t -> upper(t), tags) AS tags_upper,\n    country,\n    device,\n    revenue_cents\nFROM events;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    arrayMap(t -> upper(t), tags) AS tags_upper,\n    country,\n    device,\n    revenue_cents\nFROM events;",
    "tokens_in": 366,
    "tokens_out": 59,
    "latency_ms": 549,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_04",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    arrayMap(t -> upperUTF8(t), tags) AS tags_upper,\n    country,\n    device,\n    revenue_cents\nFROM events;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    arrayMap(t -> upperUTF8(t), tags) AS tags_upper,\n    country,\n    device,\n    revenue_cents\nFROM events;",
    "tokens_in": 366,
    "tokens_out": 61,
    "latency_ms": 526,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_04",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    arrayMap(t -> upper(t), tags) AS tags_upper,\n    country,\n    device,\n    revenue_cents\nFROM events;",
    "raw_response": "SELECT\n    event_id,\n    timestamp,\n    user_id,\n    event_type,\n    page,\n    duration_ms,\n    properties,\n    arrayMap(t -> upper(t), tags) AS tags_upper,\n    country,\n    device,\n    revenue_cents\nFROM events;",
    "tokens_in": 366,
    "tokens_out": 59,
    "latency_ms": 540,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_05",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    argMax(user_id, total_duration_ms) AS user_id,\n    max(total_duration_ms) AS total_duration_ms\nFROM\n(\n    SELECT\n        event_type,\n        user_id,\n        sum(ifNull(duration_ms, 0)) AS total_duration_ms\n    FROM events\n    GROUP BY\n        event_type,\n        user_id\n)\nGROUP BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    argMax(user_id, total_duration_ms) AS user_id,\n    max(total_duration_ms) AS total_duration_ms\nFROM\n(\n    SELECT\n        event_type,\n        user_id,\n        sum(ifNull(duration_ms, 0)) AS total_duration_ms\n    FROM events\n    GROUP BY\n        event_type,\n        user_id\n)\nGROUP BY event_type;",
    "tokens_in": 371,
    "tokens_out": 258,
    "latency_ms": 633,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_05",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    argMax(user_id, total_duration_ms) AS user_id,\n    max(total_duration_ms) AS total_duration_ms\nFROM\n(\n    SELECT\n        event_type,\n        user_id,\n        sum(ifNull(duration_ms, 0)) AS total_duration_ms\n    FROM events\n    GROUP BY\n        event_type,\n        user_id\n)\nGROUP BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    argMax(user_id, total_duration_ms) AS user_id,\n    max(total_duration_ms) AS total_duration_ms\nFROM\n(\n    SELECT\n        event_type,\n        user_id,\n        sum(ifNull(duration_ms, 0)) AS total_duration_ms\n    FROM events\n    GROUP BY\n        event_type,\n        user_id\n)\nGROUP BY event_type;",
    "tokens_in": 371,
    "tokens_out": 212,
    "latency_ms": 560,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_05",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    event_type,\n    argMax(user_id, total_duration_ms) AS user_id_with_longest_total_duration,\n    max(total_duration_ms) AS longest_total_duration_ms\nFROM\n(\n    SELECT\n        event_type,\n        user_id,\n        sum(coalesce(duration_ms, 0)) AS total_duration_ms\n    FROM events\n    GROUP BY\n        event_type,\n        user_id\n)\nGROUP BY event_type;",
    "raw_response": "SELECT\n    event_type,\n    argMax(user_id, total_duration_ms) AS user_id_with_longest_total_duration,\n    max(total_duration_ms) AS longest_total_duration_ms\nFROM\n(\n    SELECT\n        event_type,\n        user_id,\n        sum(coalesce(duration_ms, 0)) AS total_duration_ms\n    FROM events\n    GROUP BY\n        event_type,\n        user_id\n)\nGROUP BY event_type;",
    "tokens_in": 371,
    "tokens_out": 256,
    "latency_ms": 629,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_06",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    day,\n    count() AS event_count\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-02-01 00:00:00', 3, 'UTC')\nGROUP BY\n    day = toDate(timestamp)\nORDER BY day\nWITH FILL\n    FROM toDate('2024-01-01')\n    TO   toDate('2024-02-01')\n    STEP 1;",
    "raw_response": "SELECT\n    day,\n    count() AS event_count\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-02-01 00:00:00', 3, 'UTC')\nGROUP BY\n    day = toDate(timestamp)\nORDER BY day\nWITH FILL\n    FROM toDate('2024-01-01')\n    TO   toDate('2024-02-01')\n    STEP 1;",
    "tokens_in": 373,
    "tokens_out": 123,
    "latency_ms": 584,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_06",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    day,\n    count() AS event_count\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-02-01 00:00:00', 3, 'UTC')\nGROUP BY\n    day = toDate(timestamp)\nORDER BY day\nWITH FILL\n    FROM toDate('2024-01-01')\n    TO   toDate('2024-02-01')\n    STEP 1;",
    "raw_response": "SELECT\n    day,\n    count() AS event_count\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-02-01 00:00:00', 3, 'UTC')\nGROUP BY\n    day = toDate(timestamp)\nORDER BY day\nWITH FILL\n    FROM toDate('2024-01-01')\n    TO   toDate('2024-02-01')\n    STEP 1;",
    "tokens_in": 373,
    "tokens_out": 123,
    "latency_ms": 1599,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_06",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    day,\n    count() AS event_count\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-02-01 00:00:00', 3, 'UTC')\nGROUP BY day := toDate(timestamp)\nORDER BY day\nWITH FILL\n    FROM toDate('2024-01-01')\n    TO toDate('2024-02-01')\n    STEP 1;",
    "raw_response": "SELECT\n    day,\n    count() AS event_count\nFROM events\nWHERE timestamp >= toDateTime64('2024-01-01 00:00:00', 3, 'UTC')\n  AND timestamp <  toDateTime64('2024-02-01 00:00:00', 3, 'UTC')\nGROUP BY day := toDate(timestamp)\nORDER BY day\nWITH FILL\n    FROM toDate('2024-01-01')\n    TO toDate('2024-02-01')\n    STEP 1;",
    "tokens_in": 373,
    "tokens_out": 120,
    "latency_ms": 587,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_07",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    arraySort(groupArray(event_type)) AS event_types_sorted\nFROM events\nGROUP BY user_id;",
    "raw_response": "SELECT\n    user_id,\n    arraySort(groupArray(event_type)) AS event_types_sorted\nFROM events\nGROUP BY user_id;",
    "tokens_in": 367,
    "tokens_out": 31,
    "latency_ms": 531,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_07",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    arraySort(groupArray(event_type)) AS event_types_sorted\nFROM events\nGROUP BY user_id;",
    "raw_response": "SELECT\n    user_id,\n    arraySort(groupArray(event_type)) AS event_types_sorted\nFROM events\nGROUP BY user_id;",
    "tokens_in": 367,
    "tokens_out": 31,
    "latency_ms": 507,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_07",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    arraySort(groupArray(event_type)) AS event_types_sorted\nFROM events\nGROUP BY user_id;",
    "raw_response": "SELECT\n    user_id,\n    arraySort(groupArray(event_type)) AS event_types_sorted\nFROM events\nGROUP BY user_id;",
    "tokens_in": 367,
    "tokens_out": 31,
    "latency_ms": 635,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_08",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    argMax(event_id, timestamp) AS event_id,\n    max(timestamp) AS timestamp,\n    argMax(event_type, timestamp) AS event_type,\n    argMax(page, timestamp) AS page,\n    argMax(duration_ms, timestamp) AS duration_ms,\n    argMax(properties, timestamp) AS properties,\n    argMax(tags, timestamp) AS tags,\n    argMax(country, timestamp) AS country,\n    argMax(device, timestamp) AS device,\n    argMax(revenue_cents, timestamp) AS revenue_cents\nFROM events\nGROUP BY user_id;",
    "raw_response": "SELECT\n    user_id,\n    argMax(event_id, timestamp) AS event_id,\n    max(timestamp) AS timestamp,\n    argMax(event_type, timestamp) AS event_type,\n    argMax(page, timestamp) AS page,\n    argMax(duration_ms, timestamp) AS duration_ms,\n    argMax(properties, timestamp) AS properties,\n    argMax(tags, timestamp) AS tags,\n    argMax(country, timestamp) AS country,\n    argMax(device, timestamp) AS device,\n    argMax(revenue_cents, timestamp) AS revenue_cents\nFROM events\nGROUP BY user_id;",
    "tokens_in": 364,
    "tokens_out": 126,
    "latency_ms": 604,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_08",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    argMax(event_id, timestamp)        AS event_id,\n    max(timestamp)                     AS timestamp,\n    argMax(event_type, timestamp)      AS event_type,\n    argMax(page, timestamp)            AS page,\n    argMax(duration_ms, timestamp)     AS duration_ms,\n    argMax(properties, timestamp)      AS properties,\n    argMax(tags, timestamp)            AS tags,\n    argMax(country, timestamp)         AS country,\n    argMax(device, timestamp)          AS device,\n    argMax(revenue_cents, timestamp)   AS revenue_cents\nFROM events\nGROUP BY user_id;",
    "raw_response": "SELECT\n    user_id,\n    argMax(event_id, timestamp)        AS event_id,\n    max(timestamp)                     AS timestamp,\n    argMax(event_type, timestamp)      AS event_type,\n    argMax(page, timestamp)            AS page,\n    argMax(duration_ms, timestamp)     AS duration_ms,\n    argMax(properties, timestamp)      AS properties,\n    argMax(tags, timestamp)            AS tags,\n    argMax(country, timestamp)         AS country,\n    argMax(device, timestamp)          AS device,\n    argMax(revenue_cents, timestamp)   AS revenue_cents\nFROM events\nGROUP BY user_id;",
    "tokens_in": 364,
    "tokens_out": 136,
    "latency_ms": 496,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_08",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    argMax(event_id, timestamp) AS most_recent_event_id,\n    max(timestamp) AS most_recent_timestamp,\n    argMax(event_type, timestamp) AS most_recent_event_type,\n    argMax(page, timestamp) AS most_recent_page,\n    argMax(duration_ms, timestamp) AS most_recent_duration_ms,\n    argMax(properties, timestamp) AS most_recent_properties,\n    argMax(tags, timestamp) AS most_recent_tags,\n    argMax(country, timestamp) AS most_recent_country,\n    argMax(device, timestamp) AS most_recent_device,\n    argMax(revenue_cents, timestamp) AS most_recent_revenue_cents\nFROM events\nGROUP BY user_id;",
    "raw_response": "SELECT\n    user_id,\n    argMax(event_id, timestamp) AS most_recent_event_id,\n    max(timestamp) AS most_recent_timestamp,\n    argMax(event_type, timestamp) AS most_recent_event_type,\n    argMax(page, timestamp) AS most_recent_page,\n    argMax(duration_ms, timestamp) AS most_recent_duration_ms,\n    argMax(properties, timestamp) AS most_recent_properties,\n    argMax(tags, timestamp) AS most_recent_tags,\n    argMax(country, timestamp) AS most_recent_country,\n    argMax(device, timestamp) AS most_recent_device,\n    argMax(revenue_cents, timestamp) AS most_recent_revenue_cents\nFROM events\nGROUP BY user_id;",
    "tokens_in": 364,
    "tokens_out": 147,
    "latency_ms": 553,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_09",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH\n    toDateTime('2024-06-15 00:00:00', 'UTC') AS day_start\nSELECT\n    hours.h AS hour,\n    coalesce(e.cnt, 0) AS event_count\nFROM\n(\n    SELECT\n        addHours(day_start, number) AS h\n    FROM numbers(24)\n) AS hours\nLEFT JOIN\n(\n    SELECT\n        toStartOfHour(timestamp) AS h,\n        count() AS cnt\n    FROM events\n    WHERE timestamp >= day_start\n      AND timestamp < addDays(day_start, 1)\n    GROUP BY h\n) AS e\nON e.h = hours.h\nORDER BY hour;",
    "raw_response": "WITH\n    toDateTime('2024-06-15 00:00:00', 'UTC') AS day_start\nSELECT\n    hours.h AS hour,\n    coalesce(e.cnt, 0) AS event_count\nFROM\n(\n    SELECT\n        addHours(day_start, number) AS h\n    FROM numbers(24)\n) AS hours\nLEFT JOIN\n(\n    SELECT\n        toStartOfHour(timestamp) AS h,\n        count() AS cnt\n    FROM events\n    WHERE timestamp >= day_start\n      AND timestamp < addDays(day_start, 1)\n    GROUP BY h\n) AS e\nON e.h = hours.h\nORDER BY hour;",
    "tokens_in": 378,
    "tokens_out": 146,
    "latency_ms": 529,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_09",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH\n    toDateTime('2024-06-15 00:00:00', 'UTC') AS day_start,\n    day_start + INTERVAL 1 DAY AS day_end\nSELECT\n    h AS hour_start,\n    coalesce(e.cnt, 0) AS event_count\nFROM\n(\n    SELECT\n        addHours(day_start, number) AS h\n    FROM numbers(24)\n) AS hours\nLEFT JOIN\n(\n    SELECT\n        toStartOfHour(timestamp) AS hour_start,\n        count() AS cnt\n    FROM events\n    WHERE timestamp >= day_start\n      AND timestamp < day_end\n    GROUP BY hour_start\n) AS e\nON e.hour_start = hours.h\nORDER BY hour_start;",
    "raw_response": "WITH\n    toDateTime('2024-06-15 00:00:00', 'UTC') AS day_start,\n    day_start + INTERVAL 1 DAY AS day_end\nSELECT\n    h AS hour_start,\n    coalesce(e.cnt, 0) AS event_count\nFROM\n(\n    SELECT\n        addHours(day_start, number) AS h\n    FROM numbers(24)\n) AS hours\nLEFT JOIN\n(\n    SELECT\n        toStartOfHour(timestamp) AS hour_start,\n        count() AS cnt\n    FROM events\n    WHERE timestamp >= day_start\n      AND timestamp < day_end\n    GROUP BY hour_start\n) AS e\nON e.hour_start = hours.h\nORDER BY hour_start;",
    "tokens_in": 378,
    "tokens_out": 158,
    "latency_ms": 543,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_09",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "WITH hours AS\n(\n    SELECT toDateTime64('2024-06-15 00:00:00', 3, 'UTC') + number * INTERVAL 1 HOUR AS hour\n    FROM numbers(24)\n)\nSELECT\n    h.hour,\n    coalesce(e.cnt, 0) AS event_count\nFROM hours AS h\nLEFT JOIN\n(\n    SELECT\n        toStartOfHour(timestamp) AS hour,\n        count() AS cnt\n    FROM events\n    WHERE timestamp >= toDateTime64('2024-06-15 00:00:00', 3, 'UTC')\n      AND timestamp <  toDateTime64('2024-06-16 00:00:00', 3, 'UTC')\n    GROUP BY hour\n) AS e\nON h.hour = e.hour\nORDER BY h.hour;",
    "raw_response": "WITH hours AS\n(\n    SELECT toDateTime64('2024-06-15 00:00:00', 3, 'UTC') + number * INTERVAL 1 HOUR AS hour\n    FROM numbers(24)\n)\nSELECT\n    h.hour,\n    coalesce(e.cnt, 0) AS event_count\nFROM hours AS h\nLEFT JOIN\n(\n    SELECT\n        toStartOfHour(timestamp) AS hour,\n        count() AS cnt\n    FROM events\n    WHERE timestamp >= toDateTime64('2024-06-15 00:00:00', 3, 'UTC')\n      AND timestamp <  toDateTime64('2024-06-16 00:00:00', 3, 'UTC')\n    GROUP BY hour\n) AS e\nON h.hour = e.hour\nORDER BY h.hour;",
    "tokens_in": 378,
    "tokens_out": 184,
    "latency_ms": 522,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_10",
    "run": 1,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    arrayDistinct(arrayFlatten(groupArray(arrayFilter(t -> positionCaseInsensitive(t, 'premium') > 0, tags)))) AS premium_tags\nFROM events\nGROUP BY user_id\nHAVING length(premium_tags) > 0;",
    "raw_response": "SELECT\n    user_id,\n    arrayDistinct(arrayFlatten(groupArray(arrayFilter(t -> positionCaseInsensitive(t, 'premium') > 0, tags)))) AS premium_tags\nFROM events\nGROUP BY user_id\nHAVING length(premium_tags) > 0;",
    "tokens_in": 382,
    "tokens_out": 58,
    "latency_ms": 578,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_10",
    "run": 2,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    arrayDistinct(\n        arrayFlatten(\n            groupArray(\n                arrayFilter(t -> positionCaseInsensitiveUTF8(t, 'premium') > 0, tags)\n            )\n        )\n    ) AS premium_tags\nFROM events\nGROUP BY user_id\nHAVING length(premium_tags) > 0;",
    "raw_response": "SELECT\n    user_id,\n    arrayDistinct(\n        arrayFlatten(\n            groupArray(\n                arrayFilter(t -> positionCaseInsensitiveUTF8(t, 'premium') > 0, tags)\n            )\n        )\n    ) AS premium_tags\nFROM events\nGROUP BY user_id\nHAVING length(premium_tags) > 0;",
    "tokens_in": 382,
    "tokens_out": 72,
    "latency_ms": 678,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  },
  {
    "model": "gpt-5.2",
    "model_id": "openai/gpt-5.2",
    "question_id": "t5_10",
    "run": 3,
    "tier": 5,
    "prompt_type": "zero-shot",
    "extracted_sql": "SELECT\n    user_id,\n    arrayDistinct(\n        arrayFlatten(\n            groupArray(\n                arrayFilter(t -> positionCaseInsensitiveUTF8(t, 'premium') > 0, tags)\n            )\n        )\n    ) AS premium_tags\nFROM events\nGROUP BY user_id\nHAVING length(premium_tags) > 0;",
    "raw_response": "SELECT\n    user_id,\n    arrayDistinct(\n        arrayFlatten(\n            groupArray(\n                arrayFilter(t -> positionCaseInsensitiveUTF8(t, 'premium') > 0, tags)\n            )\n        )\n    ) AS premium_tags\nFROM events\nGROUP BY user_id\nHAVING length(premium_tags) > 0;",
    "tokens_in": 382,
    "tokens_out": 72,
    "latency_ms": 541,
    "model_id_returned": "openai/gpt-5.2",
    "error": null
  }
]